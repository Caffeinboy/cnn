{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMw8xRyelcC2fqiwVEStjnT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Caffeinboy/cnn/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD_60jyxWsj9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert MNIST image files into tensor of 4D(#if image,height,width)\n",
        "transform = transforms.ToTensor()"
      ],
      "metadata": {
        "id": "9H1Qd4dzbG0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "FmbaHJT3bjd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test data\n",
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "A7NlL5Y9b7C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "GvHBV5oEcUUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "XoIZ88GrcYz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "Ne3YHN76ceGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "wiCVIyKichLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "id": "FwuJCM9vcicq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "FuLlLrjycrCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd cnn_data"
      ],
      "metadata": {
        "id": "gP7XAUGYcsaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "a-xvzflSczEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "id": "-eOfTh_Dc1iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "T00_l2iAc8IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd content"
      ],
      "metadata": {
        "id": "lUT06kJLc_2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a small batch size image\n",
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(train_data, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "I_W2waQgdCEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define our CNN model\n",
        "#describe convolutional layers & its doing(2 layers)\n",
        "conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "conv2 = nn.Conv2d(6, 16, 3, 1)"
      ],
      "metadata": {
        "id": "5_7ehTpAdx4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grab 1 MNIST image/record\n",
        "for i, (x_train,y_train) in enumerate(train_data):\n",
        "  break"
      ],
      "metadata": {
        "id": "7moBa_6SeceL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "roZZPWdEe_Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x_train.view(1,1,28,28)"
      ],
      "metadata": {
        "id": "-n_QuWPZfCsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform the 1st convolution\n",
        "x = x_train.view(1,1,28,28) # Re-initialize x with the original input shape\n",
        "x = F.relu(conv1(x)) #Rectified linear unit for our activation function"
      ],
      "metadata": {
        "id": "t1sMc6XxfHgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#single image,6 is the filters asked for 26x26\n",
        "x.shape"
      ],
      "metadata": {
        "id": "u6GiX_j9ffwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pass thru the pooling\n",
        "x = F.max_pool2d(x, 2,2)#kernal of 2 & stride of 2"
      ],
      "metadata": {
        "id": "HE_5PasagGFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #26 / 2 = 13"
      ],
      "metadata": {
        "id": "NvzRPMVBmnKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do 2nd convolusional layer\n",
        "x = F.relu(conv2(x))"
      ],
      "metadata": {
        "id": "tlKHaPWWmsDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #loose padding since we didn't set em so lose 2 px"
      ],
      "metadata": {
        "id": "cCH6aCoBnEIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pooling layer\n",
        "x = F.max_pool2d(x, 2,2)"
      ],
      "metadata": {
        "id": "WuEFwRg8nGTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape # 11 / 2 =5.5 --> 5"
      ],
      "metadata": {
        "id": "VF1cwjjCnZ_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model class\n",
        "class convolusionalNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "    #fully connected layer\n",
        "    self.fc1 = nn.Linear(5*5*16, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2,2) # 2x2 kernal & stride of 2\n",
        "\n",
        "    #second pass\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2,2)\n",
        "\n",
        "    #Re-view to flatten it out\n",
        "    x = x.view(-1, 5*5*16)\n",
        "\n",
        "    #fully connected layers\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "cL5bc0EfneBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an instance of our model\n",
        "torch.manual_seed(101)\n",
        "model = convolusionalNetwork()\n",
        "model"
      ],
      "metadata": {
        "id": "4DcDFUZapj0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.008) #smaller learning rate,longer it takes"
      ],
      "metadata": {
        "id": "7H1phQ1YqH-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "#create variables to track things\n",
        "epochs = 30\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "\n",
        "#For loop of epochs\n",
        "for i in range(epochs):\n",
        "  trn_corr = 0\n",
        "  tst_corr = 0\n",
        "\n",
        "\n",
        "  #Train\n",
        "  for b,(x_train, y_train) in enumerate(train_loader):\n",
        "    b += 1\n",
        "    y_pred = model(x_train) #get predicted values\n",
        "    loss = criterion(y_pred, y_train) #off the compare prediction\n",
        "    predicted = torch.max(y_pred.data, 1)[1]#add the no of correct prediction\n",
        "    batch_corr = (predicted == y_train).sum() #how many got correct\n",
        "    trn_corr += batch_corr\n",
        "\n",
        "\n",
        "    #update our parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_losses.append(loss)\n",
        "    train_correct.append(trn_corr)\n",
        "\n",
        "\n",
        "  #print out some results\n",
        "  if b%60 == 0:\n",
        "     print(f'epoch: {i} batch: {b} loss: {loss.item()}')\n",
        "\n",
        "  train_losses.append(loss)\n",
        "  train_correct.append(trn_corr)\n",
        "\n",
        "  #Test\n",
        "  with torch.no_grad():\n",
        "   for b,(x_test, y_test) in enumerate(test_loader):\n",
        "    y_val = model(x_test)\n",
        "    predicted = torch.max(y_val.data, 1)[1]\n",
        "    tst_corr += (predicted == y_test).sum()\n",
        "\n",
        "  loss = criterion(y_val, y_test)\n",
        "  test_losses.append(loss)\n",
        "  test_correct.append(tst_corr)\n",
        "\n",
        "  current_time = time.time()\n",
        "  total = current_time - start_time\n",
        "  print(f'Training tool: {total/60}minutes!')"
      ],
      "metadata": {
        "id": "R6Vw0m0eqiWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only convert if they're tensors, otherwise leave them\n",
        "plt.plot([t.item() for t in train_losses], label=\"Training Loss\")\n",
        "plt.plot([t.item() for t in test_losses], label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss per Epoch\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ocpF97mUt8qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graph the accuracy end of epoch\n",
        "plt.plot([t/600 for t in train_correct], label='Training Accuracy')\n",
        "plt.plot([t/100 for t in test_correct], label='Testing Accuracy')\n",
        "plt.title('Training & Testing Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "DeUyzkz_xgST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}